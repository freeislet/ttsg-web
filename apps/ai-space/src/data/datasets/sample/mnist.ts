import * as tf from '@tensorflow/tfjs'
import { BaseDataset } from '../BaseDataset'
import { IDataset } from '../../types'
import { 
  fetchAndDecompress, 
  parseIDXImages, 
  parseIDXLabels, 
  getCacheKey, 
  loadFromCache, 
  saveToCache, 
  isCacheExpired 
} from '../../../utils/dataLoader'

// MNIST ë°ì´í„° ìƒìˆ˜
const IMAGE_HEIGHT = 28
const IMAGE_WIDTH = 28
const IMAGE_FLAT_SIZE = IMAGE_HEIGHT * IMAGE_WIDTH
const LABEL_FLAT_SIZE = 10

// MNIST ë°ì´í„° URL (TensorFlow Datasets ê³µì‹)
const MNIST_BASE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'
const MNIST_TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'
const MNIST_TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'
const MNIST_TEST_IMAGES = 't10k-images-idx3-ubyte.gz'
const MNIST_TEST_LABELS = 't10k-labels-idx1-ubyte.gz'

/**
 * MNIST ë°ì´í„°ì…‹ í´ë˜ìŠ¤
 */
class MNISTDataset extends BaseDataset {
  readonly inputs: tf.Tensor
  readonly labels: tf.Tensor
  readonly inputShape: number[] = [28, 28, 1]
  readonly outputShape: number[] = [10]
  readonly inputColumns: string[] = ['pixel']
  readonly outputColumns: string[] = ['digit']
  readonly sampleCount: number

  readonly trainInputs: tf.Tensor
  readonly trainLabels: tf.Tensor
  readonly testInputs: tf.Tensor
  readonly testLabels: tf.Tensor
  readonly trainCount: number
  readonly testCount: number

  constructor(
    trainImages: tf.Tensor,
    trainLabels: tf.Tensor,
    testImages: tf.Tensor,
    testLabels: tf.Tensor
  ) {
    super()

    // í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
    this.trainInputs = trainImages
    this.trainLabels = trainLabels
    this.testInputs = testImages
    this.testLabels = testLabels

    this.trainCount = trainImages.shape[0]
    this.testCount = testImages.shape[0]
    this.sampleCount = this.trainCount + this.testCount

    // ì „ì²´ ë°ì´í„° ê²°í•©
    this.inputs = tf.concat([trainImages, testImages], 0)
    this.labels = tf.concat([trainLabels, testLabels], 0)
  }

  dispose(): void {
    super.dispose()
    // ì¶”ê°€ ì •ë¦¬ ì‘ì—…ì´ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì— êµ¬í˜„
  }
}


/**
 * ì‹¤ì œ MNIST ë°ì´í„°ë¥¼ URLì—ì„œ ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤
 */
class MNISTDataLoader {
  private trainImages: Float32Array[] | null = null
  private trainLabels: Uint8Array[] | null = null
  private testImages: Float32Array[] | null = null
  private testLabels: Uint8Array[] | null = null

  async load(): Promise<void> {
    console.log('ğŸŒ Loading MNIST data from official sources...')
    
    try {
      // ë³‘ë ¬ë¡œ ëª¨ë“  íŒŒì¼ ë¡œë“œ
      const [trainImagesData, trainLabelsData, testImagesData, testLabelsData] = await Promise.all([
        this.loadFile(MNIST_BASE_URL + MNIST_TRAIN_IMAGES, 'train_images'),
        this.loadFile(MNIST_BASE_URL + MNIST_TRAIN_LABELS, 'train_labels'),
        this.loadFile(MNIST_BASE_URL + MNIST_TEST_IMAGES, 'test_images'),
        this.loadFile(MNIST_BASE_URL + MNIST_TEST_LABELS, 'test_labels')
      ])

      // IDX íŒŒì¼ íŒŒì‹±
      this.trainImages = parseIDXImages(trainImagesData)
      this.trainLabels = parseIDXLabels(trainLabelsData, LABEL_FLAT_SIZE)
      this.testImages = parseIDXImages(testImagesData)
      this.testLabels = parseIDXLabels(testLabelsData, LABEL_FLAT_SIZE)

      console.log('âœ… MNIST data loaded successfully')
      console.log(`ğŸ“Š Train: ${this.trainImages.length} images, Test: ${this.testImages.length} images`)
    } catch (error) {
      console.error('âŒ Failed to load MNIST data:', error)
      throw error
    }
  }

  private async loadFile(url: string, type: string): Promise<ArrayBuffer> {
    const cacheKey = getCacheKey(url)
    
    // ìºì‹œ í™•ì¸
    if (!isCacheExpired(cacheKey)) {
      const cached = loadFromCache(cacheKey)
      if (cached) {
        console.log(`ğŸ’¾ Using cached ${type} data`)
        return cached
      }
    }

    // ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
    console.log(`ğŸ“¥ Downloading ${type} from ${url}`)
    const buffer = await fetchAndDecompress(url)
    
    // ìºì‹œ ì €ì¥
    saveToCache(cacheKey, buffer)
    
    return buffer
  }

  getTrainData(): { images: Float32Array[], labels: Uint8Array[] } {
    if (!this.trainImages || !this.trainLabels) {
      throw new Error('Data not loaded. Call load() first.')
    }
    return { images: this.trainImages, labels: this.trainLabels }
  }

  getTestData(): { images: Float32Array[], labels: Uint8Array[] } {
    if (!this.testImages || !this.testLabels) {
      throw new Error('Data not loaded. Call load() first.')
    }
    return { images: this.testImages, labels: this.testLabels }
  }
}

/**
 * MNIST ë°ì´í„°ì…‹ ë¡œë” (ì‹¤ì œ URLì—ì„œ ë¡œë“œ)
 */
export async function loadMNIST(): Promise<IDataset> {
  console.log('ğŸš€ Loading MNIST dataset from remote URLs...')

  try {
    const loader = new MNISTDataLoader()
    await loader.load()

    const trainData = loader.getTrainData()
    const testData = loader.getTestData()

    // ì´ë¯¸ì§€ í…ì„œ ìƒì„± (4D: [batch, height, width, channels])
    const trainImagesTensor = tf.tensor4d(
      trainData.images.reduce((acc, img) => acc.concat(Array.from(img)), [] as number[]),
      [trainData.images.length, IMAGE_HEIGHT, IMAGE_WIDTH, 1]
    )

    const testImagesTensor = tf.tensor4d(
      testData.images.reduce((acc, img) => acc.concat(Array.from(img)), [] as number[]),
      [testData.images.length, IMAGE_HEIGHT, IMAGE_WIDTH, 1]
    )

    // ë¼ë²¨ í…ì„œ ìƒì„± (ì´ë¯¸ ì›-í•« ì¸ì½”ë”©ë¨)
    const trainLabelsTensor = tf.tensor2d(
      trainData.labels.reduce((acc, label) => acc.concat(Array.from(label)), [] as number[]),
      [trainData.labels.length, LABEL_FLAT_SIZE]
    ).toFloat()

    const testLabelsTensor = tf.tensor2d(
      testData.labels.reduce((acc, label) => acc.concat(Array.from(label)), [] as number[]),
      [testData.labels.length, LABEL_FLAT_SIZE]
    ).toFloat()

    const dataset = new MNISTDataset(
      trainImagesTensor,
      trainLabelsTensor,
      testImagesTensor,
      testLabelsTensor
    )

    console.log('âœ… MNIST dataset loaded successfully')
    console.log(`ğŸ“Š Train samples: ${dataset.trainCount}, Test samples: ${dataset.testCount}`)

    return dataset
  } catch (error) {
    console.error('âŒ Failed to load MNIST dataset:', error)
    // ì‹¤íŒ¨ ì‹œ í´ë°±ìœ¼ë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    console.log('ğŸ”„ Falling back to sample data...')
    return loadMNISTSample()
  }
}

/**
 * í´ë°±ìš© ìƒ˜í”Œ MNIST ë°ì´í„° ìƒì„±
 */
function generateSampleMNISTData(numSamples: number): {
  images: Float32Array[]
  labels: number[]
} {
  const images: Float32Array[] = []
  const labels: number[] = []

  for (let i = 0; i < numSamples; i++) {
    const image = new Float32Array(IMAGE_FLAT_SIZE)
    const digit = i % 10
    
    for (let j = 0; j < IMAGE_FLAT_SIZE; j++) {
      const row = Math.floor(j / IMAGE_WIDTH)
      const col = j % IMAGE_WIDTH
      
      if (row >= 8 && row <= 20 && col >= 8 && col <= 20) {
        switch (digit) {
          case 0:
            const centerX = 14, centerY = 14
            const distance = Math.sqrt((row - centerY) ** 2 + (col - centerX) ** 2)
            image[j] = distance >= 4 && distance <= 6 ? 0.8 + Math.random() * 0.2 : Math.random() * 0.1
            break
          case 1:
            image[j] = col >= 13 && col <= 15 ? 0.8 + Math.random() * 0.2 : Math.random() * 0.1
            break
          default:
            image[j] = Math.random() > 0.7 ? 0.6 + Math.random() * 0.4 : Math.random() * 0.1
        }
      } else {
        image[j] = Math.random() * 0.1
      }
    }
    
    images.push(image)
    labels.push(digit)
  }

  return { images, labels }
}

/**
 * í´ë°±ìš© ìƒ˜í”Œ MNIST ë°ì´í„°ì…‹ ë¡œë”
 */
async function loadMNISTSample(): Promise<IDataset> {
  console.log('ğŸ“Š Generating sample MNIST data...')
  
  const trainData = generateSampleMNISTData(1000)
  const testData = generateSampleMNISTData(200)

  const trainImagesTensor = tf.tensor4d(
    trainData.images.reduce((acc, img) => acc.concat(Array.from(img)), [] as number[]),
    [trainData.images.length, IMAGE_HEIGHT, IMAGE_WIDTH, 1]
  )

  const trainLabelsTensor = tf
    .oneHot(tf.tensor1d(trainData.labels, 'int32'), LABEL_FLAT_SIZE)
    .toFloat()

  const testImagesTensor = tf.tensor4d(
    testData.images.reduce((acc, img) => acc.concat(Array.from(img)), [] as number[]),
    [testData.images.length, IMAGE_HEIGHT, IMAGE_WIDTH, 1]
  )

  const testLabelsTensor = tf.oneHot(tf.tensor1d(testData.labels, 'int32'), LABEL_FLAT_SIZE).toFloat()

  return new MNISTDataset(
    trainImagesTensor,
    trainLabelsTensor,
    testImagesTensor,
    testLabelsTensor
  )
}

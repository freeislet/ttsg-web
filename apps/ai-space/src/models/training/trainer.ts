import * as tf from '@tensorflow/tfjs'
import { ModelTrainingConfig, TrainingResult, TrainingCallbacks, TrainingProgress } from './types'
import { createOptimizer } from './optimizers'
import { createDefaultCallbacks, createEarlyStoppingCallback, combineCallbacks } from './callbacks'

/**
 * ë²”ìš© ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ í´ë˜ìŠ¤
 * ëª¨ë“  TensorFlow.js ëª¨ë¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í›ˆë ¨ ì‹œìŠ¤í…œ
 */
export class ModelTrainer {
  private startTime: number = 0

  /**
   * ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
   * @param model í›ˆë ¨í•  TensorFlow.js ëª¨ë¸
   * @param trainX í›ˆë ¨ ì…ë ¥ ë°ì´í„°
   * @param config í›ˆë ¨ ì„¤ì •
   * @param callbacks í›ˆë ¨ ì½œë°±ë“¤
   * @returns í›ˆë ¨ ê²°ê³¼
   */
  async train(
    model: tf.Sequential,
    trainX: tf.Tensor | tf.Tensor[],
    trainY: tf.Tensor | tf.Tensor[],
    config: ModelTrainingConfig,
    callbacks?: TrainingCallbacks
  ): Promise<TrainingResult> {
    const trainId = `train_${Date.now()}_${Math.random().toString(36).substr(2, 5)}`
    console.log(`ğŸ“ [${trainId}] ModelTrainer.train started`)

    this.startTime = Date.now()

    // ì½œë°± ê²°í•©
    console.log(`ğŸ“ [${trainId}] Creating callbacks...`)
    const defaultCallbacks = createDefaultCallbacks()
    const combinedCallbacks = combineCallbacks(defaultCallbacks, callbacks || {})

    // ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
    let earlyStoppingCallback: ReturnType<typeof createEarlyStoppingCallback> | null = null
    if (config.earlyStoppingPatience && config.earlyStoppingPatience > 0) {
      console.log(
        `ğŸ“ [${trainId}] Setting up early stopping (patience: ${config.earlyStoppingPatience})`
      )
      earlyStoppingCallback = createEarlyStoppingCallback(config.earlyStoppingPatience)
      Object.assign(
        combinedCallbacks,
        combineCallbacks(combinedCallbacks, earlyStoppingCallback.callback)
      )
    }

    try {
      // í›ˆë ¨ ì‹œì‘ ì½œë°±
      console.log(`ğŸ“ [${trainId}] Calling onTrainStart callback...`)
      await combinedCallbacks.onTrainStart?.()

      // TensorFlow.js ë°±ì—”ë“œ í™•ì¸
      console.log(`ğŸ“ [${trainId}] Checking TensorFlow.js backend:`, tf.getBackend())

      // ì˜µí‹°ë§ˆì´ì € ìƒì„±
      console.log(
        `ğŸ“ [${trainId}] Creating optimizer (${config.optimizer}, lr: ${config.learningRate})...`
      )
      const optimizer = createOptimizer(config.optimizer, config.learningRate)

      // TensorFlow.js ë°±ì—”ë“œ ì´ˆê¸°í™” í™•ì¸ (ë°±ì—”ë“œ ì˜¤ë¥˜ ë°©ì§€)
      await tf.ready()
      if (!tf.getBackend()) {
        console.log(`ğŸ”§ [${trainId}] Initializing TensorFlow.js backend...`)
        await tf.setBackend('webgl').catch(async () => {
          console.log(`ğŸ”§ [${trainId}] WebGL failed, using CPU backend...`)
          await tf.setBackend('cpu')
        })
      }
      console.log(`ğŸ”§ [${trainId}] Backend ready:`, tf.getBackend())

      // ëª¨ë¸ ì»´íŒŒì¼
      model.compile({
        optimizer,
        loss: config.loss,
        metrics: config.metrics || ['accuracy'],
      })

      console.log(`âœ… [${trainId}] Model compiled successfully`)

      // ì‹¤ì œ ë°ì´í„° ê²€ì‚¬ ë° ë¹„êµ
      console.log(`ğŸ” [${trainId}] Analyzing training data...`)

      // trainX ë°ì´í„° ê²€ì‚¬
      console.log(`ğŸ“Š [${trainId}] trainX info:`, {
        shape: Array.isArray(trainX) ? trainX.map((t) => t.shape) : trainX.shape,
        dtype: Array.isArray(trainX) ? trainX.map((t) => t.dtype) : trainX.dtype,
        size: Array.isArray(trainX) ? trainX.map((t) => t.size) : trainX.size,
      })

      // trainY ë°ì´í„° ê²€ì‚¬
      console.log(`ğŸ¯ [${trainId}] trainY info:`, {
        shape: Array.isArray(trainY) ? trainY.map((t) => t.shape) : trainY.shape,
        dtype: Array.isArray(trainY) ? trainY.map((t) => t.dtype) : trainY.dtype,
        size: Array.isArray(trainY) ? trainY.map((t) => t.size) : trainY.size,
      })

      // ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥ (ì²« 5ê°œ ìƒ˜í”Œ) - ì•ˆì „í•œ ë°©ì‹
      console.log(`ğŸ” [${trainId}] Attempting safe data sampling...`)
      try {
        // WebGL ë°±ì—”ë“œ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ CPUë¡œ ì„ì‹œ ì „í™˜
        const currentBackend = tf.getBackend()
        console.log(`ğŸ”§ [${trainId}] Current backend for sampling:`, currentBackend)
        
        if (currentBackend === 'webgl') {
          console.log(`ğŸ”§ [${trainId}] Switching to CPU for safe data sampling...`)
          await tf.setBackend('cpu')
        }
        
        if (Array.isArray(trainX)) {
          const trainXShape = trainX[0].shape
          const trainYTensor = Array.isArray(trainY) ? trainY[0] : trainY
          const trainYShape = trainYTensor.shape
          
          console.log(`ğŸ” [${trainId}] trainX[0] shape:`, trainXShape)
          console.log(`ğŸ” [${trainId}] trainY shape:`, trainYShape)
          
          // ë” ì•ˆì „í•œ slice ì‚¬ì´ì¦ˆ
          const sampleSize = Math.min(3, trainXShape[0]) // 5ì—ì„œ 3ìœ¼ë¡œ ì¶•ì†Œ
          const xSlice = trainX[0].slice([0], [sampleSize])
          const ySlice = trainYTensor.slice([0], [sampleSize])
          
          console.log(`ğŸ” [${trainId}] trainX[0] sample (${sampleSize} items):`, await xSlice.data())
          console.log(`ğŸ” [${trainId}] trainY sample (${sampleSize} items):`, await ySlice.data())
          
          // ë©”ëª¨ë¦¬ ì •ë¦¬
          xSlice.dispose()
          ySlice.dispose()
        } else {
          // trainXê°€ Tensorì¸ì§€ í™•ì¸
          if (trainX && typeof trainX.shape !== 'undefined' && typeof trainX.slice === 'function') {
            const trainXShape = trainX.shape
            const trainYTensor = Array.isArray(trainY) ? trainY[0] : trainY
            const trainYShape = trainYTensor.shape
            
            console.log(`ğŸ” [${trainId}] trainX shape:`, trainXShape)
            console.log(`ğŸ” [${trainId}] trainY shape:`, trainYShape)
            
            const sampleSize = Math.min(3, trainXShape[0])
            const xSlice = trainX.slice([0], [sampleSize])
            const ySlice = trainYTensor.slice([0], [sampleSize])
            
            console.log(`ğŸ” [${trainId}] trainX sample (${sampleSize} items):`, await xSlice.data())
            console.log(`ğŸ” [${trainId}] trainY sample (${sampleSize} items):`, await ySlice.data())
            
            xSlice.dispose()
            ySlice.dispose()
          } else {
            console.warn(`ğŸ”´ [${trainId}] trainX is not a valid Tensor:`, trainX)
          }
        }
        
        // ë°±ì—”ë“œ ë³µì›
        if (currentBackend === 'webgl') {
          console.log(`ğŸ”§ [${trainId}] Switching back to WebGL...`)
          await tf.setBackend('webgl')
        }
        
      } catch (sampleError) {
        console.error(`ğŸ”´ [${trainId}] Error sampling data:`, sampleError)
        console.log(`ğŸ”§ [${trainId}] Skipping data sampling due to backend issues`)
      }

      // ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (ì•ˆì „í•œ ë°©ì‹)
      console.log(`ğŸ©º [${trainId}] Performing safe data health check...`)
      try {
        const checkTensorHealthSafe = async (tensor: any, name: string) => {
          try {
            // ë°±ì—”ë“œ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ CPUë¡œ ì„ì‹œ ì „í™˜
            const currentBackend = tf.getBackend()
            if (currentBackend === 'webgl') {
              await tf.setBackend('cpu')
            }
            
            // ì‘ì€ ìƒ˜í”Œë§Œ ê²€ì‚¬
            const sampleSize = Math.min(100, tensor.size) // ì „ì²´ ë°ì´í„° ëŒ€ì‹  100ê°œë§Œ
            const sample = tensor.slice([0], [Math.min(sampleSize, tensor.shape[0])])
            const data = await sample.data()
            
            const hasNaN = data.some((val: number) => isNaN(val))
            const hasInf = data.some((val: number) => !isFinite(val))
            const dataArray = Array.from(data) as number[]
            const min = Math.min(...dataArray)
            const max = Math.max(...dataArray)

            console.log(`ğŸ©º [${trainId}] ${name} health check (sample: ${data.length}/${tensor.size}):`, {
              hasNaN,
              hasInf,
              min,
              max,
              totalSize: tensor.size,
              shape: tensor.shape
            })

            if (hasNaN || hasInf) {
              console.error(`ğŸ’¥ [${trainId}] ${name} contains invalid values!`)
            }
            
            sample.dispose()
            
            // ë°±ì—”ë“œ ë³µì›
            if (currentBackend === 'webgl') {
              await tf.setBackend('webgl')
            }
            
          } catch (innerError) {
            console.error(`ğŸ”´ [${trainId}] Failed to check ${name}:`, innerError)
          }
        }

        if (Array.isArray(trainX)) {
          await checkTensorHealthSafe(trainX[0], 'trainX[0]')
          if (Array.isArray(trainY)) {
            await checkTensorHealthSafe(trainY[0], 'trainY[0]')
          } else {
            await checkTensorHealthSafe(trainY, 'trainY')
          }
        } else {
          await checkTensorHealthSafe(trainX, 'trainX')
          await checkTensorHealthSafe(trainY, 'trainY')
        }
      } catch (healthError) {
        console.error(`ğŸ”´ [${trainId}] Error in safe health check:`, healthError)
        console.log(`ğŸ”§ [${trainId}] Skipping detailed health check due to backend issues`)
      }

      // í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ ë¹„êµë¥¼ ìœ„í•´ ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„±
      console.log(`ğŸ§ª [${trainId}] Creating test model with simple data...`)
      model = tf.sequential()
      model.add(tf.layers.dense({ units: 1, inputShape: [1] }))
      model.compile({ loss: 'meanSquaredError', optimizer: 'sgd' })
      const xs = tf.tensor2d([-1, 0, 1, 2, 3, 4], [6, 1])
      const ys = tf.tensor2d([-3, -1, 1, 3, 5, 7], [6, 1])

      console.log(`ğŸ§ª [${trainId}] Test data shapes - xs:`, xs.shape, 'ys:', ys.shape)
      await model.fit(xs, ys, {
        epochs: 3, // ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        verbose: 1,
      })
      console.log(`âœ… [${trainId}] Test model training successful!`)

      // í›ˆë ¨ ì‹¤í–‰
      console.log(`ğŸ“ [${trainId}] Starting model.fit...`)
      console.log(`ğŸ“ [${trainId}] Training config:`, {
        epochs: config.epochs,
        batchSize: config.batchSize,
        validationSplit: config.validationSplit || 0.2,
        shuffle: config.shuffle ?? true,
        verbose: config.verbose ?? 0,
      })

      // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•™ìŠµ (ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ìµœì†Œ ì„¤ì •ë§Œ)
      console.log(`ğŸƒ [${trainId}] Starting simplified training...`)
      // const history = await model.fit(trainX, trainY, {
      const history = await model.fit(xs, ys, {
        epochs: config.epochs,
        batchSize: config.batchSize,
        validationSplit: config.validationSplit || 0.2,
        shuffle: config.shuffle ?? true,
        verbose: config.verbose ?? 0,
        callbacks: {
          onEpochEnd: async (epoch: number, logs?: tf.Logs) => {
            console.log(`ğŸ“ [${trainId}] Epoch ${epoch + 1} completed:`, logs)
            const logRecord = logs || {}

            // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            const progress: TrainingProgress = {
              epoch: epoch + 1,
              totalEpochs: config.epochs,
              logs: logRecord,
              elapsedTime: Date.now() - this.startTime,
              estimatedTimeRemaining: this.calculateEstimatedTime(epoch + 1, config.epochs),
            }

            await combinedCallbacks.onEpochEnd?.(epoch, logRecord)
            await combinedCallbacks.onProgress?.(progress)

            // ì¡°ê¸° ì¢…ë£Œ í™•ì¸
            if (earlyStoppingCallback?.shouldStop()) {
              console.log(`ğŸ“ [${trainId}] Early stopping triggered`)
              model.stopTraining = true
            }
          },
        },
      })

      console.log(`ğŸ“ [${trainId}] model.fit completed successfully`)

      // í›ˆë ¨ ê²°ê³¼ ìƒì„±
      // const trainingHistory = extractMetrics(history)
      // const bestEpoch = findBestEpoch(trainingHistory)

      console.log(`âœ… [${trainId}] Simplified training completed successfully`)
      console.log(`ğŸ“ˆ [${trainId}] Training history keys:`, Object.keys(history.history))

      // ì‹œë¼íŠ¸ í›ˆë ¨ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ë°©ì§€)
      const duration = Date.now() - this.startTime
      const finalLoss = Array.isArray(history.history.loss)
        ? history.history.loss[history.history.loss.length - 1]
        : 0

      // ì•ˆì „í•œ íˆìŠ¤í† ë¦¬ ì¶”ì¶œ
      const extractSafeHistory = (historyData: any): number[] => {
        if (Array.isArray(historyData)) {
          return historyData.map((val: any) => (typeof val === 'number' ? val : 0))
        }
        return []
      }

      const extractSafeValue = (historyData: any): number | undefined => {
        if (Array.isArray(historyData) && historyData.length > 0) {
          const lastVal = historyData[historyData.length - 1]
          return typeof lastVal === 'number' ? lastVal : undefined
        }
        return undefined
      }

      const result: TrainingResult = {
        history: {
          loss: extractSafeHistory(history.history.loss),
          accuracy: extractSafeHistory(history.history.acc || history.history.accuracy),
          valLoss: extractSafeHistory(history.history.val_loss),
          valAccuracy: extractSafeHistory(history.history.val_acc || history.history.val_accuracy),
        },
        finalMetrics: {
          loss: typeof finalLoss === 'number' ? finalLoss : 0,
          ...(extractSafeValue(history.history.acc || history.history.accuracy) !== undefined && {
            accuracy: extractSafeValue(history.history.acc || history.history.accuracy)!,
          }),
        },
        epochs: Array.isArray(history.history.loss) ? history.history.loss.length : 0,
        duration,
        bestEpoch: 0, // ì‹œë¼íŠ¸ ë²„ì „ì—ì„œëŠ” 0ìœ¼ë¡œ ì„¤ì •
        stopped: true,
        stoppedReason: 'completed',
      }

      // ê°„ë‹¨í•œ ê²°ê³¼ ë¦¬í¬íŒ…
      console.log(`ğŸ“ˆ [${trainId}] Final loss:`, finalLoss)
      if (result.finalMetrics.accuracy !== undefined) {
        console.log(`ğŸ“ˆ [${trainId}] Final accuracy:`, result.finalMetrics.accuracy)
      }

      // í›ˆë ¨ ì™„ë£Œ ì½œë°± (ì•ˆì „í•˜ê²Œ ì‹¤í–‰)
      try {
        await combinedCallbacks.onTrainEnd?.(result)
      } catch (callbackError) {
        console.warn(`ğŸ”´ [${trainId}] Callback error (non-critical):`, callbackError)
      }

      return result
    } catch (error) {
      const trainingError = error instanceof Error ? error : new Error(String(error))

      console.error(`ğŸ“ [${trainId}] Training error caught:`, {
        message: trainingError.message,
        stack: trainingError.stack,
        name: trainingError.name,
      })

      await combinedCallbacks.onError?.(trainingError)

      // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
      const duration = Date.now() - this.startTime
      const result: TrainingResult = {
        history: { loss: [] },
        finalMetrics: {},
        epochs: 0,
        duration,
        stopped: true,
        stoppedReason: 'error',
      }

      throw trainingError
    } finally {
      // ë©”ëª¨ë¦¬ ì •ë¦¬ (ì•ˆì „í•œ dispose)
      try {
        if (Array.isArray(trainX)) {
          trainX.forEach((tensor) => {
            if (tensor && !tensor.isDisposed) {
              tensor.dispose()
            }
          })
        } else if (trainX && !trainX.isDisposed) {
          trainX.dispose()
        }

        if (Array.isArray(trainY)) {
          trainY.forEach((tensor) => {
            if (tensor && !tensor.isDisposed) {
              tensor.dispose()
            }
          })
        } else if (trainY && !trainY.isDisposed) {
          trainY.dispose()
        }
      } catch (disposeError) {
        console.warn('âš ï¸ Tensor dispose warning:', disposeError)
      }
    }
  }

  /**
   * ë‚¨ì€ ì‹œê°„ ì¶”ì •
   * @param currentEpoch í˜„ì¬ ì—í¬í¬
   * @param totalEpochs ì´ ì—í¬í¬ ìˆ˜
   * @returns ì¶”ì • ë‚¨ì€ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
   */
  private calculateEstimatedTime(currentEpoch: number, totalEpochs: number): number {
    if (currentEpoch === 0) return 0

    const elapsedTime = Date.now() - this.startTime
    const timePerEpoch = elapsedTime / currentEpoch
    const remainingEpochs = totalEpochs - currentEpoch

    return remainingEpochs * timePerEpoch
  }

  /**
   * ëª¨ë¸ í‰ê°€
   * @param model í‰ê°€í•  ëª¨ë¸
   * @param testX í…ŒìŠ¤íŠ¸ ì…ë ¥ ë°ì´í„°
   * @param testY í…ŒìŠ¤íŠ¸ ì¶œë ¥ ë°ì´í„°
   * @returns í‰ê°€ ê²°ê³¼
   */
  async evaluate(
    model: tf.LayersModel,
    testX: tf.Tensor | tf.Tensor[],
    testY: tf.Tensor | tf.Tensor[]
  ): Promise<Record<string, number>> {
    try {
      const evalResult = model.evaluate(testX, testY)

      if (Array.isArray(evalResult)) {
        const metrics: Record<string, number> = {}
        const metricNames = model.metricsNames || ['loss']

        evalResult.forEach((tensor, index) => {
          const metricName = metricNames[index] || `metric_${index}`
          metrics[metricName] = tensor.dataSync()[0]
          tensor.dispose()
        })

        return metrics
      } else {
        const loss = evalResult.dataSync()[0]
        evalResult.dispose()
        return { loss }
      }
    } catch (error) {
      console.error('Model evaluation failed:', error)
      throw error
    }
  }

  /**
   * ëª¨ë¸ ì˜ˆì¸¡
   * @param model ì˜ˆì¸¡í•  ëª¨ë¸
   * @param inputData ì…ë ¥ ë°ì´í„°
   * @returns ì˜ˆì¸¡ ê²°ê³¼
   */
  predict(model: tf.LayersModel, inputData: tf.Tensor | tf.Tensor[]): tf.Tensor | tf.Tensor[] {
    return model.predict(inputData)
  }
}
